Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	annot_table
	1	blastp
	1	merge_GO_and_KEGG_annotation
	1	pfam
	1	signalp
	6

[Sun Feb 12 18:20:07 2023]
Job 2: Blastp vs SwissProt..


[Sun Feb 12 18:20:07 2023]
Job 3: Hmmscan using PFAM..

[Sun Feb 12 18:20:07 2023]
Error in rule pfam:
    jobid: 3
    output: PFAM.out
    shell:
        hmmscan --cpu 2 -E 0.001 --domE 0.001 --domtblout PFAM.out DB/Pfam-A.hmm protein.faa > pfam.log
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

[Sun Feb 12 18:20:08 2023]
Error in rule blastp:
    jobid: 2
    output: blastp_sprot.outfmt6
    shell:
        diamond blastp --threads 2 --max-target-seqs 1 --evalue 0.001 -d DB/uniprot_sprot.fasta -q protein.faa -o blastp_sprot.outfmt6
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /scratch2/free/programs/PAP/gitPAP/example/.snakemake/log/2023-02-12T182007.691964.snakemake.log
